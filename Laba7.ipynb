{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laba7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMIDek6NllhUBlu2l1Z5mp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeataStultica/II_graphic_collab/blob/main/Laba7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHXN8wHq17g6",
        "outputId": "db64a06a-e35c-4a45-d48c-098da0f2830d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_104 (Conv2D)         (None, 54, 54, 96)        34944     \n",
            "                                                                 \n",
            " activation_181 (Activation)  (None, 54, 54, 96)       0         \n",
            "                                                                 \n",
            " max_pooling2d_96 (MaxPoolin  (None, 27, 27, 96)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_105 (Conv2D)         (None, 17, 17, 256)       2973952   \n",
            "                                                                 \n",
            " activation_182 (Activation)  (None, 17, 17, 256)      0         \n",
            "                                                                 \n",
            " max_pooling2d_97 (MaxPoolin  (None, 8, 8, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_106 (Conv2D)         (None, 6, 6, 384)         885120    \n",
            "                                                                 \n",
            " activation_183 (Activation)  (None, 6, 6, 384)        0         \n",
            "                                                                 \n",
            " conv2d_107 (Conv2D)         (None, 4, 4, 384)         1327488   \n",
            "                                                                 \n",
            " activation_184 (Activation)  (None, 4, 4, 384)        0         \n",
            "                                                                 \n",
            " conv2d_108 (Conv2D)         (None, 2, 2, 256)         884992    \n",
            "                                                                 \n",
            " activation_185 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " max_pooling2d_98 (MaxPoolin  (None, 1, 1, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_32 (Flatten)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 4096)              1052672   \n",
            "                                                                 \n",
            " activation_186 (Activation)  (None, 4096)             0         \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_187 (Activation)  (None, 4096)             0         \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 1000)              4097000   \n",
            "                                                                 \n",
            " activation_188 (Activation)  (None, 1000)             0         \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 1)                 1001      \n",
            "                                                                 \n",
            " activation_189 (Activation)  (None, 1)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,038,481\n",
            "Trainable params: 28,038,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(4096 ))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "5u9gcNkiBgsS"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 224, 224\n",
        "train_data_dir = '/content/gdrive/MyDrive/v_data/train/'\n",
        "validation_data_dir = '/content/gdrive/MyDrive/v_data/test/'\n",
        "nb_train_samples = 400\n",
        "nb_validation_samples = 100\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "if K.image_data_format() == 'channels_first':\n",
        "  input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "  input_shape = (img_width, img_height, 3)\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters=32, input_shape=input_shape, kernel_size=(2,2)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(filters=32, kernel_size=(2,2)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(filters=64, kernel_size=(2,2)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(64))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "\n",
        "model2.add(Dense(1))\n",
        "\n",
        "model2.add(Activation('sigmoid'))\n",
        "model2.summary()\n",
        "\n",
        "model2.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JWGXiuXA-cw",
        "outputId": "da6e9b6c-db7d-426e-d894-9fc69bd1e50b"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_109 (Conv2D)         (None, 223, 223, 32)      416       \n",
            "                                                                 \n",
            " activation_190 (Activation)  (None, 223, 223, 32)     0         \n",
            "                                                                 \n",
            " max_pooling2d_99 (MaxPoolin  (None, 111, 111, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_110 (Conv2D)         (None, 110, 110, 32)      4128      \n",
            "                                                                 \n",
            " activation_191 (Activation)  (None, 110, 110, 32)     0         \n",
            "                                                                 \n",
            " max_pooling2d_100 (MaxPooli  (None, 55, 55, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_111 (Conv2D)         (None, 54, 54, 64)        8256      \n",
            "                                                                 \n",
            " activation_192 (Activation)  (None, 54, 54, 64)       0         \n",
            "                                                                 \n",
            " max_pooling2d_101 (MaxPooli  (None, 27, 27, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_33 (Flatten)        (None, 46656)             0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 64)                2986048   \n",
            "                                                                 \n",
            " activation_193 (Activation)  (None, 64)               0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            " activation_194 (Activation)  (None, 1)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,998,913\n",
            "Trainable params: 2,998,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='binary')\n",
        "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDa9L39pDpvs",
        "outputId": "f888985f-813d-4000-dc5e-4f1038b07480"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Found 400 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit_generator(train_generator, steps_per_epoch=nb_train_samples//batch_size,\n",
        "                     epochs=epochs, validation_data=validation_generator, \n",
        "                     validation_steps=nb_validation_samples//batch_size)\n",
        "model2.save('laba7_binary_0.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ_HUEXIE69t",
        "outputId": "7f11a518-e169-48a8-c657-e6e99837c350"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 22s 828ms/step - loss: 0.8967 - accuracy: 0.6175 - val_loss: 0.4664 - val_accuracy: 0.7604\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 25s 987ms/step - loss: 0.4707 - accuracy: 0.7975 - val_loss: 0.2814 - val_accuracy: 0.8958\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 21s 825ms/step - loss: 0.4079 - accuracy: 0.8375 - val_loss: 0.7849 - val_accuracy: 0.6562\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 21s 827ms/step - loss: 0.4084 - accuracy: 0.8450 - val_loss: 0.2720 - val_accuracy: 0.8958\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 21s 821ms/step - loss: 0.3582 - accuracy: 0.8600 - val_loss: 0.4571 - val_accuracy: 0.7604\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 21s 818ms/step - loss: 0.3125 - accuracy: 0.8750 - val_loss: 0.4843 - val_accuracy: 0.8021\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 21s 818ms/step - loss: 0.3186 - accuracy: 0.8650 - val_loss: 0.4498 - val_accuracy: 0.8125\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 21s 820ms/step - loss: 0.2695 - accuracy: 0.8825 - val_loss: 0.4914 - val_accuracy: 0.8021\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 21s 820ms/step - loss: 0.2483 - accuracy: 0.9000 - val_loss: 0.4076 - val_accuracy: 0.8125\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 21s 818ms/step - loss: 0.2841 - accuracy: 0.8775 - val_loss: 0.2579 - val_accuracy: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "LBwtF0ncGpPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile parsing.py\n",
        "#!usr/bin/bash python\n",
        "import argparse \n",
        "from imutils import paths\n",
        "import time \n",
        "import cv2 \n",
        "import random\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "ap = argparse.ArgumentParser() \n",
        "ap.add_argument(\"-d\", \"--dataset\", type=str,help=\"path to input dataset of images\", required=True) \n",
        "ap.add_argument(\"-m\", \"--model\", required=True,type=str, help=\"File to output trained model\") \n",
        "ap.add_argument(\"-l\", \"--label\", required=True, type=str, help=\"path to output label binarizer\") \n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "data = []\n",
        "data_2 = []\n",
        "labels = []\n",
        "\n",
        "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
        "print(len(imagePaths))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)\n",
        "for imagePath in imagePaths:\n",
        "  image = cv2.imread(imagePath)\n",
        "  image = cv2.resize(image, (32,32))\n",
        "  data.append(image.flatten())\n",
        "  data_2.append(image)\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "data = np.array(data, dtype=\"float\")/255.0\n",
        "data_2 = np.array(data_2, dtype=\"float\")/255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "(trainX2, testX2, trainY2, testY2) = train_test_split(data_2, labels, test_size=0.25, random_state=42)\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "\n",
        "trainY2 = lb.transform(trainY2)\n",
        "testY2 = lb.transform(testY2)\n",
        "\n",
        "with open(args[\"label\"], 'wb') as f:\n",
        "  pickle.dump(lb, f)\n",
        "with open('trainY', 'wb') as f:\n",
        "  pickle.dump(trainY, f)\n",
        "with open('testY', 'wb') as f:\n",
        "  pickle.dump(testY, f)\n",
        "with open('testX', 'wb') as f:\n",
        "  pickle.dump(testX, f)\n",
        "with open('trainX', 'wb') as f:\n",
        "  pickle.dump(trainX, f)\n",
        "\n",
        "\n",
        "with open('trainY_3d', 'wb') as f:\n",
        "  pickle.dump(trainY2, f)\n",
        "with open('testY_3d', 'wb') as f:\n",
        "  pickle.dump(testY2, f)\n",
        "with open('testX_3d', 'wb') as f:\n",
        "  pickle.dump(testX2, f)\n",
        "with open('trainX_3d', 'wb') as f:\n",
        "  pickle.dump(trainX2, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IdIBGSEGyrS",
        "outputId": "e99cc870-8daa-464d-8870-58b980bd656a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting parsing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python parsing.py --dataset \"/content/gdrive/MyDrive/animals\" --model \"simple_nn.model\" --label \"labels7.pickle\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df22R-aBPv3R",
        "outputId": "340614d0-f956-4ccb-8d8f-ab05ed7162c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def unpickle(file):\n",
        "  with open(file, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "X_test=unpickle(\"testX_3d\")\n",
        "X_train=unpickle(\"trainX_3d\")\n",
        "Y_test=unpickle(\"testY_3d\")\n",
        "Y_train=unpickle(\"trainY_3d\")\n",
        "#print(data)\n",
        "print(Y_train.shape)\n",
        "print(X_train.shape)\n",
        "\n",
        "img_width = 32\n",
        "img_height = 32\n",
        "nb_train_samples = 2250\n",
        "nb_validation_samples = 750\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters=32, input_shape=input_shape, kernel_size=(2,2)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(filters=32, kernel_size=(2,2)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(filters=64, kernel_size=(2,2)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(256, input_shape=(32*32*3,)))#256\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "model2.add(Dense(3))\n",
        "\n",
        "model2.add(Activation('sigmoid'))\n",
        "model2.summary()\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCpM2Hy9aWzM",
        "outputId": "4cf5dada-f438-4f03-83ac-e3fa8f6d860e"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2250, 3)\n",
            "(2250, 32, 32, 3)\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_77 (Conv2D)          (None, 31, 31, 32)        416       \n",
            "                                                                 \n",
            " activation_133 (Activation)  (None, 31, 31, 32)       0         \n",
            "                                                                 \n",
            " max_pooling2d_75 (MaxPoolin  (None, 15, 15, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_78 (Conv2D)          (None, 14, 14, 32)        4128      \n",
            "                                                                 \n",
            " activation_134 (Activation)  (None, 14, 14, 32)       0         \n",
            "                                                                 \n",
            " max_pooling2d_76 (MaxPoolin  (None, 7, 7, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 6, 6, 64)          8256      \n",
            "                                                                 \n",
            " activation_135 (Activation)  (None, 6, 6, 64)         0         \n",
            "                                                                 \n",
            " max_pooling2d_77 (MaxPoolin  (None, 3, 3, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_25 (Flatten)        (None, 576)               0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 256)               147712    \n",
            "                                                                 \n",
            " activation_136 (Activation)  (None, 256)              0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 3)                 771       \n",
            "                                                                 \n",
            " activation_137 (Activation)  (None, 3)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 161,283\n",
            "Trainable params: 161,283\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "\n",
        "#drive.mount(\"/content/gdrive\")\n",
        "\n",
        "#train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#train_generator = train_datagen.flow(X_train, Y_train, batch_size=batch_size)\n",
        "#validation_generator = test_datagen.flow(X_test, Y_test, batch_size=batch_size)\n",
        "#model2.fit_generator(train_generator, \n",
        "#           epochs=epochs,  validation_data=validation_generator,\n",
        "#           steps_per_epoch=nb_train_samples//batch_size)\n",
        "model2.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, \n",
        "           validation_data=(X_test, Y_test), validation_steps=nb_validation_samples//batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pvRiFKmlvE0",
        "outputId": "22de5baf-d5ff-4ddb-d8d3-51ff3003a63b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "141/141 [==============================] - 4s 22ms/step - loss: 0.8865 - accuracy: 0.5462 - val_loss: 0.8379 - val_accuracy: 0.5394\n",
            "Epoch 2/10\n",
            "141/141 [==============================] - 3s 20ms/step - loss: 0.7421 - accuracy: 0.6444 - val_loss: 0.7046 - val_accuracy: 0.6318\n",
            "Epoch 3/10\n",
            "141/141 [==============================] - 3s 20ms/step - loss: 0.6711 - accuracy: 0.6738 - val_loss: 0.6651 - val_accuracy: 0.6780\n",
            "Epoch 4/10\n",
            "141/141 [==============================] - 3s 20ms/step - loss: 0.6232 - accuracy: 0.7013 - val_loss: 0.6986 - val_accuracy: 0.6250\n",
            "Epoch 5/10\n",
            "141/141 [==============================] - 3s 20ms/step - loss: 0.5782 - accuracy: 0.7098 - val_loss: 0.6352 - val_accuracy: 0.6793\n",
            "Epoch 6/10\n",
            "141/141 [==============================] - 3s 23ms/step - loss: 0.5383 - accuracy: 0.7578 - val_loss: 0.6495 - val_accuracy: 0.6671\n",
            "Epoch 7/10\n",
            "141/141 [==============================] - 4s 26ms/step - loss: 0.5059 - accuracy: 0.7711 - val_loss: 0.8510 - val_accuracy: 0.6522\n",
            "Epoch 8/10\n",
            "141/141 [==============================] - 3s 21ms/step - loss: 0.4654 - accuracy: 0.7876 - val_loss: 0.5949 - val_accuracy: 0.7160\n",
            "Epoch 9/10\n",
            "141/141 [==============================] - 3s 20ms/step - loss: 0.4244 - accuracy: 0.8138 - val_loss: 0.6059 - val_accuracy: 0.7106\n",
            "Epoch 10/10\n",
            "141/141 [==============================] - 3s 20ms/step - loss: 0.3876 - accuracy: 0.8333 - val_loss: 0.6607 - val_accuracy: 0.6821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3aa5797490>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model2.evaluate(X_test, Y_test)\n",
        "model2.save('laba7_animals.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVSj3gproZSO",
        "outputId": "ce1ae9ca-3af7-4688-b3bf-129b824aa69e"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 10ms/step - loss: 0.6605 - accuracy: 0.6800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multilayer model \n",
        "from keras import models, layers\n",
        "\n",
        "\n",
        "X_test=unpickle(\"testX\")\n",
        "X_train=unpickle(\"trainX\")\n",
        "Y_test=unpickle(\"testY\")\n",
        "Y_train=unpickle(\"trainY\")\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(32*32*3,)))\n",
        "network.add(layers.Dense(256, activation='relu'))\n",
        "network.add(layers.Dense(3, activation='softmax'))\n",
        "network.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "network.fit(X_train, Y_train, epochs=15, batch_size=128, validation_data=(X_test, Y_test),\n",
        "            validation_steps=nb_validation_samples//batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CyI3bTo3l-Q",
        "outputId": "bf0967e0-de3c-448c-9dd2-0f89e7bcf553"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 1.7228 - accuracy: 0.4053WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 46 batches). You may need to use the repeat() function when building your dataset.\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 1.7012 - accuracy: 0.4071 - val_loss: 1.0412 - val_accuracy: 0.3933\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.9615 - accuracy: 0.5009\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.8988 - accuracy: 0.5373\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.8525 - accuracy: 0.5591\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.8187 - accuracy: 0.5764\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.7810 - accuracy: 0.6164\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.7542 - accuracy: 0.6324\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.7556 - accuracy: 0.6204\n",
            "Epoch 9/15\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.7214 - accuracy: 0.6467\n",
            "Epoch 10/15\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.6960 - accuracy: 0.6693\n",
            "Epoch 11/15\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.6705 - accuracy: 0.6871\n",
            "Epoch 12/15\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.6638 - accuracy: 0.6893\n",
            "Epoch 13/15\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.6439 - accuracy: 0.6947\n",
            "Epoch 14/15\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.6098 - accuracy: 0.7129\n",
            "Epoch 15/15\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.6350 - accuracy: 0.7044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3aa5a01b50>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = network.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG3hBp1A4OY0",
        "outputId": "71d42395-f30f-4f21-d707-ef13014fdcf8"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step - loss: 0.8247 - accuracy: 0.5907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "swZp5_TJBedk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}